{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8335c15-bf72-4b62-861e-8c3152954e30",
   "metadata": {},
   "source": [
    "***\n",
    "## Implementation Option 2: Use `numpy`, `pandas`, and `sklearn`\n",
    "\n",
    "### If you do not prefer the one-stop Suprise solution and want more hardcore coding practices, you may implement the KNN model using `numpy`, `pandas`, and possibly `sklearn`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc555d-9f63-4b0c-afa0-72fd5ce0ae94",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#7FB3D5; font-size:2em; color:#34495E; padding:5px; border:5px solid #D7DBDD; text-align:center;\">\n",
    "<strong>A possible solution</strong>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d5051b-4101-4372-97e8-b1f71e2a81ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ data loaded\n",
      "✓ interaction matrix creation done\n",
      "✓ knn.fit done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 23348/23348 [05:47<00:00, 67.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ estimated ratings calculation done\n",
      "✓ execution done\n",
      "RMSE: 0.03854829079433337\n",
      "\n",
      "Time required to run the code completely (in HH:MM:SS):  00:07:08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # import the TQDM library\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "starttime = time.time()\n",
    "\n",
    "# Load the data\n",
    "rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\n",
    "data_temp = pd.read_csv(rating_url)\n",
    "data_temp['rating'] = data_temp['rating'].astype(float)\n",
    "\n",
    "l = data_temp.user.tolist()\n",
    "l = set(l) # --> len(l) will be 33901\n",
    "\n",
    "# reduce the size: user list is randomly divided into thirds\n",
    "random.seed(42)\n",
    "user_sample = random.sample(l, len(l)//3) # -->len(user_sample) will be 11300\n",
    "\n",
    "# data is a reduced/randomly filtered dataframe:\n",
    "data = data_temp.loc[data_temp['user'].isin(user_sample)] # --> data.shape will be (77824, 3)\n",
    "del data_temp\n",
    "print(u'\\u2713'+\" data loaded\")\n",
    "\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "interaction_matrix = data.pivot_table(index='user', columns='item', values='rating')\n",
    "interaction_matrix = interaction_matrix.fillna(0)\n",
    "n_users, n_items = interaction_matrix.shape\n",
    "print(u'\\u2713'+\" interaction matrix creation done\")\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3)\n",
    "\n",
    "# Calculate the similarity matrix\n",
    "similarity_matrix = cosine_similarity(interaction_matrix)\n",
    "\n",
    "# Find the k nearest neighbors for each user\n",
    "k = 3\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(interaction_matrix)\n",
    "print(u'\\u2713'+\" knn.fit done\")\n",
    "\n",
    "# Calculate the estimated ratings for the test set\n",
    "actual_ratings = []\n",
    "estimated_ratings = []\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data)): # use tqdm to create a progress bar    \n",
    "    user = row['user']\n",
    "    item = row['item']\n",
    "    rating = row['rating']\n",
    "    actual_ratings.append(rating)\n",
    "\n",
    "    # Find the k nearest neighbors for the user in the training set\n",
    "    neighbors = knn.kneighbors([interaction_matrix.loc[user]], return_distance=False)[0]\n",
    "\n",
    "    # Calculate the average rating for the item among the k nearest neighbors\n",
    "    item_ratings = []\n",
    "    for neighbor in neighbors:\n",
    "        rating = interaction_matrix.iloc[neighbor][item]\n",
    "        if rating > 0:\n",
    "            item_ratings.append(rating)\n",
    "    if len(item_ratings) > 0:\n",
    "        estimated_rating = np.mean(item_ratings)\n",
    "    else:\n",
    "        estimated_rating = 0\n",
    "    estimated_ratings.append(estimated_rating)\n",
    "\n",
    "print(u'\\u2713'+\" estimated ratings calculation done\")\n",
    "\n",
    "\n",
    "# Calculate the RMSE for the test set\n",
    "rmse = sqrt(mean_squared_error(actual_ratings, estimated_ratings))\n",
    "print(u'\\u2713'+\" execution done\")\n",
    "print(f\"RMSE: {rmse}\\n\")\n",
    "\n",
    "endtime = time.time()\n",
    "execution_time = time.strftime(\"%H:%M:%S\", time.gmtime(endtime-starttime))\n",
    "print(\"Time required to run the code completely (in HH:MM:SS): \", execution_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a01ecd-b596-42ce-a842-f2bc79ba7d46",
   "metadata": {},
   "source": [
    "<font size=5 color=#FAD7A0>Summary</font>\n",
    "\n",
    "<font size=4 color=#FAD7A0>Although <code>KNN</code> is a fairly straightforward algorithm, it is relatively memory-intensive.<br>\n",
    "→ As you saw above, I actually took a third of the available data and worked with that.<br>\n",
    "→ I also chose a relatively low number of 'k's (k=3)<br>\n",
    "Both were made with memory in mind. The run still took me just over seven minutes.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "><font size=4 color=#FAD7A0>Please note: you can increase the accuracy by using the entire available dataset and by finding the optimal number of 'k'. There are some methods to find the best `k`, although I didn't implement it here, because the memory was my priority.<br>\n",
    "Keep in mind the following: if there are sufficient resources, the optimal procedure would be <code style=\"color:#34495E; background-color:#2ECC71;\">to run the algorithm on the entire dataframe with different neighbour numbers</code> and then <code style=\"color:#34495E; background-color:#2ECC71;\">select the most accurate one</code>.\n",
    "    \n",
    "</font>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
